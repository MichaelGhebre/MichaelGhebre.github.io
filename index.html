---
layout: default
---
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Michael A Ghebre, PhD by MichaelGhebre</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      
      <section>
        <h1>
        <a id="about" class="anchor" href="#about" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Variable selection in clustering</h1>
        
 
    <p>We proposed a new method to select variables for model-based clustering (Gaussian mixture model optimized using the EM-algorithm). 
      The optimal numbers of clusters are identified using BIC (Bayesian information criterion), in which the smaller is the better. 
      Here, I will show if selecting clustering relevant variables will improve the identification of the optimal number of clusters 
      using real and simulated datasets in R. First, I will brief the theory of model-based clustering and show how the results are affected due to initialisation of the EM-algorithm</p>
        </section>
   
      <section>
        <h1>
        <a id="about" class="anchor" href="#about" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model-based clustering</h1>
        <h2>Gaussian mixture model </h2>
        <p> A Gaussian mixture model is a model-based clustering technique in which each component probability distribution (mixture component) is corresponding to a cluster. It assumes that the observed data come from heterogeneous (two or more) populations instead of from a single (homogeneous) population,it works by modeling each of the sub-populations separately and the overall population as a mixture of these sub-populations. The optimal mixture components (clusters) and cluster memberships are estimated using maximum likelihood, which is optimized using EM algorithm.   </p>
      </section>
     
      
      <section>
        <h1>
        <a id="about" class="anchor" href="#about" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Gausian mixture in R</h1>
       We wrote R function to implement the model-based clustering from scratch. The EM-algorithm is initialized using several heuristic-clustering techniques, such as kmeans, kmedoids and hierarchical, here is the code. The singularity issue was dealt by adding small value to the diagonal of the variance-covariance matrix if the variance covariance is not positive definite, here is the code.  <h2>R code for mixture model </h2>
      </section>
      
      <footer>
        <p><small> Michael A Ghebre, PhD </small></p>
        <p class="view"><a href="https://github.com/MichaelGhebre">View My GitHub Profile</a></p>
      </footer>
    </div>
  
    <script src="javascripts/scale.fix.js"></script>

  
  </body>
  

</html>
